---
layout: default
---

<strong>Gradient descent</strong>

<img style="float: left; width: 450px;" src="/assets/img/grad_descent.jpeg">
	
<p align="justify">
To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient of the function at the current point.<br />
<a href="https://en.wikipedia.org/wiki/Gradient_descent"> source </a>
</p>

<strong>Stochastic gradient descent (SGD)</strong>
<p align="justify">
A stochastic approximation of the gradient descent for minimizing an objective function that is a sum of functions.
The true gradient is approximated by the gradient of a randomly chosen single function.<br />
<a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent"> source </a>
</p>

<strong>Learning rate</strong>
<p align="justify">
The scalar by which the negative of the gradient is multiplied in gradient descent.
</p>

<strong>Backpropagation</strong>
<p align="justify">
An algorithm, relying on an iterative application of the chain rule, for computing efficiently the derivative of a neural network with respect to all of its parameters and feature vectors.<br />
<a href="https://en.wikipedia.org/wiki/Backpropagation"> source </a>
</p>

<strong>Goal function</strong>
<p align="justify">
The function being minimized in an optimization process, such as SGD.
</p>

<strong>Added noise</strong>
<p align="justify">
A perturbation added to the input of the network or one of the feature vectors it computes.
</p>

[back](cheat_sheet)
