---
layout: titlepage
---

The spectacular recent successes of deep learning are purely empirical. Nevertheless intellectuals always try to explain important developments theoretically. In this literature course we will review recent work of Burna and Mallat, Mhaskar and Poggio, Papayan and Elad, Bolsckei and co-authors, Baraniuk and co-authors, and others, seeking to build theoretical frameworks deriving deep networks as consequences. After initial background lectures, we will have some of the authors presenting lectures on specific papers. This course meets once weekly.


These are notes for Stanford statistics course **Theories of Deep Learning**. For questions/concerns/bug reports, please contact [David Donoho](https://profiles.stanford.edu/david-donoho) or [Hatef Monajemi](http://web.stanford.edu/~monajemi/).

# [](#hw)Assignments
TBA

# [](#topics)Topics

1.  [Readings] (readings)

